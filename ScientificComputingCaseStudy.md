##Case Study: Paradigms for Scientific Computing

MapReduce has become an increasingly popular programming paradigm for many data analytics applications to process data in parallel.

In many application areas, particularly in Scientific Computing, MapReduce has never been used and is not being adopted.

The purpose of this case study is to explore some of the reasons why this might be the case.

We have selected a papers and a blog areticle for you to read as part of this activity:

Jha, Somesh, et al. "A tale of two data-intensive paradigms: Applications, abstractions, and architectures." **Big Data (BigData Congress)**, 2014 IEEE International Congress on. IEEE, 2014.

Glenn Lockwood (2014) "Hadoop's Uncomfortable Fit in HPC', Available at: *http://glennklockwood.blogspot.co.uk/2014/05/hadoops-uncomfortable-fit-in-hpc.html* (Accessed: 2nd December 2015).




###Consider these questions:

1. Where is the MPI programming paradigm used?

2. What are the differences between the MPI and MapReduce programming paradigms?

3. What Scientific Computing applications have not adopted MapReduce? 
What do you think the reasons for this might be? 
Is it worth adopting MapReduce? 
How difficult it is to adapt an MPI parallel application to the MapReduce model?

4. Are there differences in efficiency for the two programming models (MapReduce and MPI)? Where do they exist?

5. Are there any Scientific Computing application areas that could adopt MapReduce? 
How might this improve efficiency.
